<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Mt-Aligner by nihowma</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Mt-Aligner</h1>
        <p>Open Source effort to create a Machine Translation based Alignment tool. Also known as Mount Aligner.</p>

        <p class="view"><a href="https://github.com/nihowma/MT-Aligner">View the Project on GitHub <small>nihowma/MT-Aligner</small></a></p>


        <ul>
          <li><a href="https://github.com/nihowma/MT-Aligner/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/nihowma/MT-Aligner/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/nihowma/MT-Aligner">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <h3>
<a id="welcome-to-mt-aligner-mount-aligner" class="anchor" href="#welcome-to-mt-aligner-mount-aligner" aria-hidden="true"><span class="octicon octicon-link"></span></a>Welcome to MT Aligner (mount aligner)</h3>

<p>This automatic Translation Memory and Machine Translation Engine trainer is an experimental project. The concept is based on seeding a Machine Translation Engine (SMT-based) with an unreliable corpus (the source text) and a parallel unreliable output model (target text). </p>

<p>The corpus files are "auto-aligned" using <a href="https://github.com/danielvarga/hunalign">Hunalign</a> or similar tools <a href="http://sourceforge.net/projects/aligner/">LF align</a> that generate information about the source and target texts--however, unlike these tools, the goal is not <em>only</em> a Translation Memory for later re-use, but a training set of data for an MT engine. </p>

<p>Eventually, a mock-training set can be generated by the MT engine and then the alignment tools used to verify/validate it. The objective is to create a reliable language model for the parallel corpora not just a useful artifact (Translation Memory).</p>

<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>Currently a work in progress... You can be a contributor or guinea pig! 
please send a note to <a href="https://github.com/nihowma" class="user-mention">@nihowma</a> for more details. I am doing this on the side of my regular translation industry job, so if all of a sudden a passionate creator with plenty of time and talent on their hands wants to build, build, baby build! I won't be standing in the way. For the meantime this project continues.</p>

<h3>
<a id="license" class="anchor" href="#license" aria-hidden="true"><span class="octicon octicon-link"></span></a>License</h3>

<p>GNU LGPLv3; as an open source project no rights are held beyond those stated in the GNU license, feel free to expand or fork this project at will. </p>

<p><img src="https://github.com/unicorn.png" alt="My Unicorn"></p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/nihowma">nihowma</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
